{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mahjong Classification\n",
    "\n",
    "This notebook aim on aply transfer learning on vgg16 to Mahjong detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependency\n",
    "\n",
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "import keras\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "#img_width, img_height = 224, 224\n",
    "#as most of our test pattern around 40*40 , lets try some smaller size\n",
    "#reset as no batter performace in 43 classes\n",
    "img_width, img_height = 80, 80 \n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "test_data_dir = 'data/test/'\n",
    "nb_train_samples = 10800\n",
    "nb_validation_samples = 450\n",
    "#nb_test_samples = 550\n",
    "\n",
    "#nb_epoch = 100\n",
    "#it seems it cound learn more\n",
    "nb_epoch = 35\n",
    "#nb_class = 34\n",
    "# update for classify 42 pattern and backOnly\n",
    "nb_class = 43\n",
    "\n",
    "ts = time.time()\n",
    "logName = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# build the VGG16 network 'imagenet'\n",
    "model = Sequential()\n",
    "vggLayer = VGG16(include_top=False, weights=None, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "\n",
    "model.add(vggLayer)\n",
    "model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dim=nb_class, activation='softmax', name='fc2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2325 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "#load the weight \n",
    "# load weights into new model\n",
    "model.load_weights(\"weights/2017_03_10_22_47_14/weights-improvement-20-0.95.hdf5\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.25\n",
    "    drop = 0.25\n",
    "    epochs_drop = 20.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "tfBoard = keras.callbacks.TensorBoard(log_dir='./logs/'+logName+\"/\", histogram_freq=2, write_graph=True)\n",
    "filepath=\"./weights/\"+logName+\"/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, tfBoard, lrate]\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./weights/\"):\n",
    "    os.makedirs(\"./weights/\")   \n",
    "if not os.path.exists('./logs/'):\n",
    "    os.makedirs('./logs/')   \n",
    "if not os.path.exists(\"./weights/\"+logName):\n",
    "    os.makedirs(\"./weights/\"+logName)   \n",
    "if not os.path.exists('./logs/'+logName):\n",
    "    os.makedirs('./logs/'+logName)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 591 images belonging to 43 classes.\n",
      "loss: 29.67%\n",
      " acc: 94.08%\n"
     ]
    }
   ],
   "source": [
    "#code for printing the prediciton \n",
    "#predict_generator(self, generator, val_samples, max_q_size=10, nb_worker=1, pickle_safe=False)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "        )\n",
    "\n",
    "\n",
    "predicted = model.predict_generator(test_generator, val_samples=591)\n",
    "\n",
    "test_pos_class_dict = dict(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()) )\n",
    "\n",
    "\n",
    "with open(\"./predictedResult.csv\",'a') as predictedCsv:\n",
    "    predictedCsv.write( \"fileName,Org Class,Predicted Class\\n\" )\n",
    "    for idx, _ in enumerate(predicted):\n",
    "        predictedCsv.write(  str(os.path.basename(imgfilenames[idx])) +\",\"+ str(os.path.dirname(imgfilenames[idx]))+\",\"+ str(test_pos_class_dict.get( predicted[idx].argmax()))+'\\n')\n",
    "\n",
    "\n",
    "score = model.evaluate_generator(test_generator, val_samples=591)\n",
    "print (\"loss: %.2f%%\\n acc: %.2f%%\" %( score[0]*100, score[1]*100) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
